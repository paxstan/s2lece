import os
import numpy as np
from scipy.spatial.transform import Rotation as R
from input_pipeline.preprocessing import preprocess_range_image
from PIL import Image
import torch
from torch.utils.data import Dataset
import torchvision.transforms as tvf

to_tensor = tvf.Compose([tvf.ToTensor()])

# class Dataset(object):
#     """ Base class for a dataset. To be overloaded.
#     """
#     root = ''
#     img_dir = ''
#     nimg = 0
#
#     def __len__(self):
#         return self.nimg
#
#     def __repr__(self):
#         res = 'Dataset: %s\n' % self.__class__.__name__
#         res += '  %d images' % self.nimg
#         res += '\n  root: %s...\n' % self.root
#         return res


class LidarBase(Dataset):
    def __init__(self, root):
        Dataset.__init__(self)
        self.root = root

    def get_image(self, img_idx):
        folder_path = os.path.join(self.root, img_idx)
        rang = self.load_np_file(folder_path + '/range.npy')
        img = Image.fromarray(rang)
        return img

    def get_valid_range_mask(self, idx):
        folder_path = os.path.join(self.root, idx)
        mask = np.load(folder_path + '/valid_mask.npy')
        return mask

    def get_xyz(self, idx):
        folder_path = os.path.join(self.root, idx)
        xyz = np.load(folder_path + '/xyz.npy')
        return xyz

    @staticmethod
    def load_np_file(path):
        return np.load(path)


class RealPairDataset(LidarBase):
    def __init__(self, root):
        LidarBase.__init__(self, root)
        self.root = root
        self.gt_pose = np.load(f'{root}/ground_truth_pose.npy') if os.path.exists(f'{root}/ground_truth_pose.npy') \
            else None
        self.arr_corres = np.load(f'{root}/corres.npy', allow_pickle=True) if os.path.exists(
            f'{root}/corres.npy') else None
        self.npairs = self.arr_corres.shape[0]

    def __len__(self):
        self.npairs = self.arr_corres.shape[0]
        return self.npairs

    @staticmethod
    def get_homog_matrix(pose):
        """
        Transforms a pose to a homogeneous matrix
        :param pose: [x, y, z, qx, qy, qz, qw]
        :return: 4x4 homogeneous matrix
        """
        m = np.eye(4)
        rot = R.from_quat(pose[3:])
        for i in range(3):
            m[i, 3] = pose[i]
        m[0:3, 0:3] = rot.as_matrix()
        return m

    def __getitem__(self, idx):
        """ returns (img1, img2, `metadata`)
        """
        source = str(self.arr_corres[idx][0])
        target = str(self.arr_corres[idx][1])
        corres_dir = self.arr_corres[idx][2]

        img1 = self.load_np_file(os.path.join(self.root, source, 'range.npy'))
        img2 = self.load_np_file(os.path.join(self.root, target, 'range.npy'))
        mask1 = np.load(os.path.join(self.root, source, 'valid_mask.npy'))
        mask2 = np.load(os.path.join(self.root, target, 'valid_mask.npy'))

        idx1 = self.load_np_file(os.path.join(self.root, source, 'idx.npy'))
        idx2 = self.load_np_file(os.path.join(self.root, target, 'idx.npy'))

        xyz1 = self.load_np_file(os.path.join(self.root, source, 'xyz.npy'))
        xyz2 = self.load_np_file(os.path.join(self.root, target, 'xyz.npy'))

        flow = self.load_np_file(os.path.join(self.root, "correspondence", corres_dir, 'flow.npy'))
        initial_flow = self.load_np_file(os.path.join(self.root, source, 'initial_flow.npy'))
        # mask_valid_in_2 = self.load_np_file(os.path.join(self.root,
        #                                                  "correspondence", corres_dir, 'mask_valid_2.npy'))

        img1 = img1 * mask1
        img1[img1 == -0.0] = 0.0

        img2 = img2 * mask2
        img2[img2 == -0.0] = 0.0

        # h1, w1 = img1.shape
        # h2, w2 = img2.shape
        #
        # img1 = img1.reshape(-1)
        # img2 = img2.reshape(-1)
        #
        # img1[np.invert(mask1)] = 0
        # img2[np.invert(mask2)] = 0

        # reshape masks of valid pixels to image sizes
        # mask1 = mask1.reshape(h1, w1)
        # mask2 = mask2.reshape(h2, w2)

        # redefine flow mask with invalid pixels in image1 and mask generated by finding flow
        mask = (mask1 * mask2).astype(bool)

        # set flow for invalid pixels to nan, which is ignored during training
        # flow[~mask, :] = 0

        # crop image
        # img2 = Image.fromarray(img2.reshape(h1, w1))
        # img1 = Image.fromarray(img1.reshape(h1, w1))
        # img1 = img1.reshape(h1, w1)
        # img2 = img2.reshape(h2, w2)
        # img1[img1 < 0] = 0
        # img2[img2 < 0] = 0
        # img1 = (img1 - np.min(img1)) / (np.max(img1) - np.min(img1))
        # img2 = (img2 - np.min(img2)) / (np.max(img2) - np.min(img2))

        # meta = {'flow': flow.transpose((2, 0, 1)), 'initial_flow': initial_flow.transpose((2, 0, 1)),
        #         'mask1': mask1.astype(bool), 'mask2': mask2.astype(bool),
        #         'idx1': idx1, 'idx2': idx2, 'xyz1': xyz1, 'xyz2': xyz2}

        # img_a, edge_weight_a = preprocess_range_image(img1)
        # img_b, edge_weight_a = preprocess_range_image(img2)
        # flow = np.float32(metadata['flow'])
        # initial_flow = np.float32(metadata['initial_flow'])
        # flow_mask = metadata.get('flow_mask', np.ones(aflow.shape[:2], np.uint8))
        # mask1 = metadata.get('mask1', np.ones(flow.shape[:2], np.uint8))
        # mask2 = metadata.get('mask2', np.ones(flow.shape[:2], np.uint8))

        # img1 = img1.astype(float)
        # img2 = img2.astype(float)
        flow = flow.transpose((1, 2, 0))
        initial_flow = initial_flow.transpose((1, 2, 0))

        result = dict(
            img1=to_tensor(img1).to(torch.float32),
            img2=to_tensor(img2).to(torch.float32),
            flow=to_tensor(flow),
            initial_flow=to_tensor(initial_flow),
            mask1=to_tensor(mask1),
            mask2=to_tensor(mask2),
            mask=to_tensor(mask)
        )
        return result


class LidarData:
    def __init__(self, path):
        self.corres = np.load(f'{path}/corres.npy') if os.path.exists(f'{path}/corres.npy') else None
        self.idx_data = np.load(f'{path}/idx.npy') if os.path.exists(f'{path}/idx.npy') else None
        self.world_frame = np.load(f'{path}/world_frame.npy') if os.path.exists(f'{path}/world_frame.npy') else None
        self.range_data = np.load(f'{path}/range.npy') if os.path.exists(f'{path}/range.npy') else None
        self.xyz_data = np.load(f'{path}/xyz.npy') if os.path.exists(f'{path}/xyz.npy') else None
        self.valid_mask = np.load(f'{path}/valid_mask.npy') if os.path.exists(f'{path}/valid_mask.npy') else None


class SingleDataset(LidarBase):
    def __init__(self, root):
        LidarBase.__init__(self, root)
        self.root = root
        self.npairs = self.get_count()

    def get_count(self):
        abspath = os.path.abspath(self.root)
        listdir = os.listdir(abspath)
        return sum([os.path.isdir(os.path.join(abspath + "/" + dr)) for dr in listdir if dr != "correspondence"])

    def __len__(self):
        return self.npairs

    def __getitem__(self, idx):
        img = self.load_np_file(os.path.join(self.root, str(idx), 'range.npy'))
        mask = self.load_np_file(os.path.join(self.root, str(idx), 'valid_mask.npy'))
        img = img * mask
        img[img == -0.0] = 0.0

        result = dict(
            img=to_tensor(img).to(torch.float32),
            mask=to_tensor(mask),
        )
        return result
